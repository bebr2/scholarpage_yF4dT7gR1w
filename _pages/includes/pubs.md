# Paper Under Submission
<div class='paper-box'><div class='paper-box-image'><div><img src='images/RACE/1.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Joint Evaluation of Answer and Reasoning Consistency for Hallucination Detection in Large Reasoning Models](https://arxiv.org/abs/2506.04832)

**Changyue Wang**, Weihang Su, Qingyao Ai, Yiqun Liu

[**Code**](https://github.com/bebr2/RACE) <strong><span class='show_paper_citations' data='iHDgZ04AAAAJ:0EnyYjriUFMC'></span></strong>
- RACE (Reasoning and Answer Consistency Evaluation) is a framework for detecting hallucinations in Large Reasoning Models (LRMs) by jointly analyzing both reasoning traces and final answers. It detects inconsistencies and hallucinations through multi-signal analysis, achieving robust and generalizable performance across models and datasets.
</div>
</div>

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">EMNLP 2025 Main</div><img src='images/EditCoT/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Knowledge Editing through Chain-of-Thought](https://arxiv.org/abs/2412.17727)

**Changyue Wang**, Weihang Su, Qingyao Ai, Yichen Tang, Yiqun Liu

[**Code**](https://github.com/bebr2/EditCoT) <strong><span class='show_paper_citations' data='iHDgZ04AAAAJ:ufrVoPGSRksC'></span></strong>
- EditCoT is a novel knowledge editing framework that updates LLMs through iterative chain-of-thought refinement, enabling efficient integration of new knowledge without retraining. It achieves state-of-the-art performance across diverse tasks and languages, offering superior generalization, stability, and effectiveness.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACL 2025 Findings</div><img src='images/DecKER/1.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Decoupling Reasoning and Knowledge Injection for In-Context Knowledge Editing](https://aclanthology.org/2025.findings-acl.1260/)

**Changyue Wang**, Weihang Su, Qingyao Ai, Yujia Zhou, Yiqun Liu

[**Code**](https://github.com/bebr2/DecKER) <strong><span class='show_paper_citations' data='iHDgZ04AAAAJ:UebtZRa9Y70C'></span></strong>
- DecKER is a novel in-context editing framework that decouples reasoning from knowledge injection, mitigating conflicts between updated and original knowledge. It achieves significant improvements in multi-hop reasoning by preserving reasoning integrity while efficiently integrating new knowledge.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">SIGIR-AP 2024</div><img src='images/LeKUBE/1.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[LeKUBE: A Knowledge Update BEnchmark for Legal Domain](https://dl.acm.org/doi/10.1145/3673791.3698407)

**Changyue Wang**, Weihang Su, Yiran Hu, Qingyao Ai, Yueyue Wu, Cheng Luo, Yiqun Liu, Min Zhang, Shaoping Ma

[**Code**](https://github.com/bebr2/LeKUBE) <strong><span class='show_paper_citations' data='iHDgZ04AAAAJ:W7OEmFMy1HYC'></span></strong>
- LeKUBE is a comprehensive benchmark designed to evaluate knowledge update methods for legal LLMs. It highlights the unique challenges of updating legal knowledge‚Äîsuch as nuanced statutory changes and complex reasoning‚Äîrevealing a significant gap between current techniques and real-world legal needs.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACL 2024 Findings</div><img src='images/MIND/1.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Unsupervised real-time hallucination detection based on the internal states of large language models](https://aclanthology.org/2024.findings-acl.854/)

Weihang Su*, **Changyue Wang**\*, Qingyao Ai, Yiran Hu, Zhijing Wu, Yujia Zhou, Yiqun Liu

[**Code**](https://github.com/oneal2000/MIND) <strong><span class='show_paper_citations' data='iHDgZ04AAAAJ:2osOgNQ5qMEC'></span></strong>
- MIND is an unsupervised framework that detects hallucinations in LLMs by leveraging their internal states during inference for real-time analysis.
Alongside, HELM provides a comprehensive benchmark to evaluate hallucination detection across diverse models and scenarios.
</div>
</div>


- [Parametric Retrieval Augmented Generation](https://dl.acm.org/doi/abs/10.1145/3726302.3729957), Weihang Su, Yichen Tang, Qingyao Ai, Junxi Yan, **Changyue Wang**, Hongning Wang, Ziyi Ye, Yujia Zhou, Yiqun Liu. ***SIGIR 2025***
- [JuDGE: Benchmarking Judgment Document Generation for Chinese Legal System](https://dl.acm.org/doi/abs/10.1145/3726302.3730295), Weihang Su, Baoqing Yue, Qingyao Ai, Yiran Hu, Jiaqi Li, **Changyue Wang**, Kaiyuan Zhang, Yueyue Wu, Yiqun Liu. ***SIGIR 2025***
- [Pre-training for Legal Case Retrieval Based on Inter-Case Distinctions](https://dl.acm.org/doi/full/10.1145/3735127), Weihang Su, Qingyao Ai, Yueyue Wu, Anzhe Xie, **Changyue Wang**, Yixiao Ma, Haitao Li, Zhijing Wu, Yiqun Liu, Min Zhang. ***ACM TOIS***
- [Mitigating Entity-Level Hallucination in Large Language Models](https://dl.acm.org/doi/10.1145/3673791.3698403), Weihang Su, Yichen Tang, Qingyao Ai, **Changyue Wang**, Zhijing Wu, Yiqun Liu. ***SIGIR-AP 2024***